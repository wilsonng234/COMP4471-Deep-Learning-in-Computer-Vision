# COMP4471-Deep-Learning-in-Computer-Vision
HKUST COMP4471 Deep Learning in Computer Vision - Assignment Repository  

# Assignment1
> [Q1](assignment1/knn.ipynb): k-Nearest Neighbor classifier  
> The IPython Notebook knn.ipynb will walk you through implementing the kNN classifier.

> [Q2](assignment1/svm.ipynb): Training a Support Vector Machine  
> The IPython Notebook svm.ipynb will walk you through implementing the SVM classifier.

> [Q3](assignment1/softmax.ipynb): Implement a Softmax classifier  
> The IPython Notebook softmax.ipynb will walk you through implementing the Softmax classifier.

> [Q4](assignment1/two_layer_net.ipynb): Two-Layer Neural Network  
> The IPython Notebook two_layer_net.ipynb will walk you through the implementation of a two-layer neural network classifier.

> [Q5](assignment1/features.ipynb): Two-Layer Neural Network  
> The IPython Notebook features.ipynb will walk you through this exercise, in which you will examine the improvements gained by using higher-level representations as opposed to using raw pixel values.

# Assignment2
> [Q1](assignment2/FullyConnectedNets.ipynb): Fully-connected Neural Network  
The IPython notebook FullyConnectedNets.ipynb will introduce you to our modular layer design, and then use those layers to implement fully-connected networks of arbitrary depth. To optimize these models you will implement several popular update rules.

> [Q2](assignment2/BatchNormalization.ipynb): Batch Normalization  
In the IPython notebook BatchNormalization.ipynb you will implement batch normalization, and use it to train deep fully-connected networks.

> [Q3](assignment2/Dropout.ipynb): Dropout  
> The IPython notebook Dropout.ipynb will help you implement Dropout and explore its effects on model generalization.

> [Q4](assignment2/ConvolutionalNetworks.ipynb): Convolutional Networks  
> In the IPython Notebook ConvolutionalNetworks.ipynb you will implement several new layers that are commonly used in convolutional networks.

> [Q5](assignment2/PyTorch.ipynb): PyTorch / TensorFlow on CIFAR-10  
> For this last part, you will be working in either TensorFlow or PyTorch, two popular and powerful deep learning frameworks. You only need to complete ONE of these two notebooks.

# Assignment3
> [Q1](assignment3/RNN_Captioning.ipynb): Image Captioning with Vanilla RNNs  
> The Jupyter notebook RNN_Captioning.ipynb will walk you through the implementation of an image captioning system on MS-COCO using vanilla recurrent networks.

> [Q2](assignment3/LSTM_Captioning.ipynb): Image Captioning with LSTMs  
> The Jupyter notebook LSTM_Captioning.ipynb will walk you through the implementation of Long-Short Term Memory (LSTM) RNNs, and apply them to image captioning on MS-COCO.

> [Q3](assignment3/NetworkVisualization-PyTorch.ipynb): Network Visualization: Saliency maps, Class Visualization, and Fooling Images  
> The Jupyter notebooks NetworkVisualization-TensorFlow.ipynb /NetworkVisualization-PyTorch.ipynb will introduce the pretrained SqueezeNet model, compute gradients with respect to images, and use them to produce saliency maps and fooling images. Please complete only one of the notebooks (TensorFlow or PyTorch).

> [Q4](assignment3/StyleTransfer-PyTorch.ipynb): Style Transfer   
> In the Jupyter notebooks StyleTransfer-TensorFlow.ipynb/StyleTransfer-PyTorch.ipynb you will learn how to create images with the content of one image but the style of another. Please complete only one of the notebooks (TensorFlow or PyTorch).
 
> [Q5](assignment3/GANs-PyTorch.ipynb): Generative Adversarial Networks  
> In the Jupyter notebooks GANs-TensorFlow.ipynb/GANs-PyTorch.ipynb you will learn how to generate images that match a training dataset, and use these models to improve classifier performance when training on a large amount of unlabeled data and a small amount of labeled data. Please complete only one of the notebooks (TensorFlow or PyTorch).
